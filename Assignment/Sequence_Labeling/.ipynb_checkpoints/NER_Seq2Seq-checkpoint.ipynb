{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Cuda Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sys\n",
    "import os\n",
    "import string, nltk\n",
    "#nltk.download('stopwords')\n",
    "nltk.data.path.append(\"/home/ubuntu/nltk_data\")\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "import numpy as np\n",
    "import torch\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Global variable and Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pretrain Embedding from Glove, at this report, I use two pretrain glove with 100 and 300 dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqence_len = 150\n",
    "embed_len = 300\n",
    "batch_size = 512\n",
    "Vocab = []\n",
    "\n",
    "glove = pd.read_csv(\"../wordEmbedding/\"+'glove.6B.'+str(embed_len)+'d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove_embedding = {key: val.values for key, val in glove.T.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.text\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    trainX = f.read().splitlines()\n",
    "    \n",
    "with open(\"train.label\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    trainY = f.read().splitlines()\n",
    "    \n",
    "with open(\"dev.text\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    devX = f.read().splitlines()\n",
    "    \n",
    "with open(\"dev.label\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    devY = f.read().splitlines()\n",
    "    \n",
    "with open(\"test.text\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    testX = f.read().splitlines()\n",
    "    \n",
    "with open(\"test.label\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    testY = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(trainX) == len(trainY)\n",
    "for idx in range(0,len(trainX)):\n",
    "    assert len(trainX[idx].split()) == len(trainY[idx].split())\n",
    "    \n",
    "assert len(devX) == len(devY)\n",
    "for idx in range(0,len(devX)):\n",
    "    assert len(devX[idx].split()) == len(devY[idx].split())\n",
    "\n",
    "assert len(testX) == len(testY)\n",
    "for idx in range(0,len(testX)):\n",
    "    assert len(testX[idx].split()) == len(testY[idx].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max seqence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i.split()) for i in (trainX+devX+testX) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-object_type', 'B-sort', 'B-timeRange', 'I-city', 'B-rating_unit', 'I-genre', 'B-service', 'B-object_location_type', 'B-playlist_owner', 'O', 'I-movie_type', 'I-cuisine', 'I-track', 'B-facility', 'B-country', 'B-artist', 'B-condition_temperature', 'I-spatial_relation', 'B-poi', 'I-served_dish', 'I-party_size_description', 'B-movie_name', 'I-object_name', 'I-album', 'I-timeRange', 'B-state', 'I-restaurant_type', 'I-location_name', 'I-facility', 'I-object_type', 'B-current_location', 'I-object_part_of_series_type', 'B-cuisine', 'B-restaurant_type', 'I-country', 'B-album', 'I-movie_name', 'B-best_rating', 'I-poi', 'I-geographic_poi', 'B-geographic_poi', 'B-object_part_of_series_type', 'B-genre', 'B-party_size_description', 'I-music_item', 'I-object_select', 'I-restaurant_name', 'B-city', 'I-sort', 'B-object_name', 'I-object_location_type', 'I-service', 'B-entity_name', 'B-year', 'B-served_dish', 'B-condition_description', 'I-entity_name', 'I-state', 'B-playlist', 'B-track', 'B-movie_type', 'B-party_size_number', 'B-music_item', 'B-location_name', 'I-playlist_owner', 'B-object_select', 'B-restaurant_name', 'I-artist', 'I-playlist', 'B-rating_value', 'I-current_location', 'B-spatial_relation'}\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "tag=[]\n",
    "for i in (trainY+devY+testY):\n",
    "    tag = tag + i.split()\n",
    "print(set(tag))\n",
    "print(len(set(tag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_index,embedding_dict,dimension):\n",
    "    embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
    "\n",
    "    for word,index in word_index.items():\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[index]=embedding_dict[word]\n",
    "    return embedding_matrix\n",
    "\n",
    "def pad_text(encoded_reviews, seq_length):\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in encoded_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append([0]*(seq_length-len(review)) + review)\n",
    "        \n",
    "    return np.array(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
    "tokenizer.fit_on_texts(train_x+dev_x+test_x)\n",
    "\n",
    "encoded_train =tokenizer.texts_to_sequences(train_x)\n",
    "encoded_dev =tokenizer.texts_to_sequences(dev_x)\n",
    "encoded_test =tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "\n",
    "train_x = pad_text(encoded_train, seq_length = seqence_len)\n",
    "train_y = np.array([1 if label == \"pos\" else 0 for label in train_y])\n",
    "\n",
    "\n",
    "dev_x = pad_text(encoded_dev, seq_length = seqence_len)\n",
    "dev_y = np.array([1 if label == \"pos\" else 0 for label in dev_y])\n",
    "\n",
    "\n",
    "test_x = pad_text(encoded_test, seq_length = seqence_len)\n",
    "test_y = np.array([1 if label == \"pos\" else 0 for label in test_y])\n",
    "\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(dev_x), torch.from_numpy(dev_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Embedding matrix from pretrain\n",
    "- By using pretrain Glove, for each word, we map it to a representative vector\n",
    "\n",
    "Padding Text\n",
    "- To let all input sentences have the same length, so that we can train in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_index,embedding_dict,dimension):\n",
    "    embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
    "\n",
    "    for word,index in word_index.items():\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[index]=embedding_dict[word]\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def Norm(text,wordnet_lemmatizer,stop_words):\n",
    "    text = text.lower().strip()\n",
    "    text =  re.sub(' +', ' ', text)\n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            w = wordnet_lemmatizer.lemmatize(w, pos=\"v\")\n",
    "            filtered_sentence.append(w) \n",
    "    texts=\" \".join(str(x) for x in filtered_sentence)\n",
    "    return text\n",
    "\n",
    "def pad_text(encoded_reviews, seq_length):\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in encoded_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append([0]*(seq_length-len(review)) + review)\n",
    "        \n",
    "    return np.array(reviews)\n",
    "\n",
    "def LoadData(file, Vocab=Vocab):\n",
    "    with open(file, \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        contents = f.read().splitlines()\n",
    "        for line in contents:\n",
    "            try:\n",
    "                _,text,label = line.split(\"#\")\n",
    "            except:\n",
    "                continue\n",
    "            text = text.split(\" \",1)[1]\n",
    "            \n",
    "            text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "            text = Norm(text,wordnet_lemmatizer,stop_words)\n",
    "            \n",
    "            data_x.append(text)\n",
    "            data_y.append(label)\n",
    "            Vocab = Vocab + text.split(\" \")\n",
    "        return data_x, data_y, Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sandra bullock and hugh grant make a great team but this predictable romantic comedy should get a pink slip', 'those eternally devoted to the insanity of black will have an intermittently good time feel free to go get popcorn whenever hes not onscreen', 'this is wild surreal stuff but brilliant and the camera just kind of sits there and lets you look at this and its like youre going from one room to the next and none of them have any relation to the other', 'this is a harrowing movie about how parents know where all the buttons are and how to push them', 'without shakespeares eloquent language the update is dreary and sluggish']\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, Vocab = LoadData(\"../data/train.txt\",Vocab)\n",
    "dev_x, dev_y, Vocab = LoadData(\"../data/dev.txt\",Vocab)\n",
    "test_x, test_y, Vocab = LoadData(\"../data/test.txt\",Vocab)\n",
    "print(test_x[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenght of sentences distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  0.,  0.,  0.,  3.,  2.,  0.,  3.,  2.,  1.,  2., 11.,\n",
       "        10., 13., 15., 11., 15., 12., 18., 19., 18., 24., 29., 20., 28.,\n",
       "        29., 27., 25., 23., 27., 29., 25., 16., 31., 24., 28., 27., 28.,\n",
       "        39., 33., 36., 29., 37., 38., 46., 42., 38., 41., 37., 48., 48.,\n",
       "        35., 56., 35., 49., 56., 38., 40., 43., 39., 47., 47., 56., 44.,\n",
       "        46., 50., 53., 39., 42., 44., 38., 57., 53., 64., 50., 57., 52.,\n",
       "        52., 53., 50., 65., 59., 58., 53., 64., 54., 58., 69., 64., 45.,\n",
       "        70., 74., 57., 49., 59., 53., 48., 54., 55., 73., 64., 68., 49.,\n",
       "        70., 52., 78., 55., 45., 45., 52., 61., 52., 56., 60., 65., 66.,\n",
       "        61., 55., 53., 65., 60., 51., 54., 49., 58., 54., 48., 58., 54.,\n",
       "        53., 37., 53., 36., 46., 53., 52., 41., 42., 45., 44., 52., 60.,\n",
       "        37., 53., 43., 38., 37., 43., 42., 45., 46., 35., 42., 38., 33.,\n",
       "        44., 34., 38., 39., 37., 36., 38., 39., 21., 33., 47., 34., 14.,\n",
       "        20., 23., 22., 34., 26., 19., 21., 22., 19., 22., 21., 20., 16.,\n",
       "        16., 22., 15., 12., 16., 17., 12., 16., 19., 19.,  8.,  8., 11.,\n",
       "        15., 17., 27.]),\n",
       " array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "        196, 197, 198, 199]),\n",
       " <BarContainer object of 198 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Len_Sentences = [len(x) for x in train_x]\n",
    "binz = [x for x in range(1,200)]\n",
    "plt.hist(Len_Sentences, bins=binz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data, Setup Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this experiment, the data is random load for each batch, do not apply strategy same lenght sentences for each batch\n",
    "\n",
    "Base on the distribution, the squence_lenght is set to average 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
    "tokenizer.fit_on_texts(train_x+dev_x+test_x)\n",
    "\n",
    "encoded_train =tokenizer.texts_to_sequences(train_x)\n",
    "encoded_dev =tokenizer.texts_to_sequences(dev_x)\n",
    "encoded_test =tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "\n",
    "train_x = pad_text(encoded_train, seq_length = seqence_len)\n",
    "train_y = np.array([1 if label == \"pos\" else 0 for label in train_y])\n",
    "\n",
    "\n",
    "dev_x = pad_text(encoded_dev, seq_length = seqence_len)\n",
    "dev_y = np.array([1 if label == \"pos\" else 0 for label in dev_y])\n",
    "\n",
    "\n",
    "test_x = pad_text(encoded_test, seq_length = seqence_len)\n",
    "test_y = np.array([1 if label == \"pos\" else 0 for label in test_y])\n",
    "\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(dev_x), torch.from_numpy(dev_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding_matrix=create_embedding_matrix(tokenizer.word_index,embedding_dict=glove_embedding,dimension=embed_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.seq_len = 150\n",
    "        self.fc_out = nn.Linear(300, n_output)\n",
    "        \n",
    "        self.conv = nn.Conv1d(in_channels=300, out_channels=100,kernel_size=3, padding=1)\n",
    "        self.conv1 = nn.Conv1d(in_channels=300, out_channels=100,kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=300, out_channels=100,kernel_size=7, padding=3)\n",
    "        \n",
    "        self.pooling = nn.MaxPool1d(150)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward (self, input_words):                                                        # => (batch size, sent len)\n",
    "\n",
    "        batch = input_words.shape[0]\n",
    "        seq_lenght= input_words.size(1)\n",
    "        \n",
    "        embedded_words = self.embedding(input_words)                                        # => (batch_size, seq_length, n_embed)\n",
    "        embedded_words = embedded_words.permute(0,2,1)                                      # => (batch_size,  n_embed,seq_length)\n",
    "\n",
    "        x = self.conv(embedded_words)           #[512, 100, 150]\n",
    "        x = self.relu(x)\n",
    "        x = self.pooling(x)                     #[512, 100, 1]\n",
    "        \n",
    "        x1 = self.conv1(embedded_words)\n",
    "        x1 = self.relu(x1)\n",
    "        x1 = self.pooling(x1)\n",
    "        \n",
    "        x2 = self.conv2(embedded_words)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.pooling(x2)\n",
    "        \n",
    "        out = self.fc_out(torch.cat(    (x.squeeze(), x1.squeeze(), x2.squeeze() )  , 1 )            )\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab=embedding_matrix.shape[0]\n",
    "n_embed=embedding_matrix.shape[1]\n",
    "n_hidden = 512\n",
    "n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\n",
    "layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = CNN(n_vocab, n_embed, n_hidden, n_output, layers).cuda()\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "criterion = criterion.cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001, weight_decay=0.0001)\n",
    "\n",
    "# print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/taco/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/80 Step: 50 Training Loss: 0.5984 Validation Loss: 0.6646\n",
      "Epoch: 7/80 Step: 100 Training Loss: 0.5504 Validation Loss: 0.6447\n",
      "Epoch: 10/80 Step: 150 Training Loss: 0.4741 Validation Loss: 0.6339\n",
      "Epoch: 13/80 Step: 200 Training Loss: 0.4278 Validation Loss: 0.6187\n",
      "Epoch: 16/80 Step: 250 Training Loss: 0.3746 Validation Loss: 0.6123\n",
      "Epoch: 20/80 Step: 300 Training Loss: 0.3130 Validation Loss: 0.6039\n",
      "Epoch: 24/80 Step: 350 Training Loss: 0.2756 Validation Loss: 0.5987\n",
      "Epoch: 28/80 Step: 400 Training Loss: 0.2304 Validation Loss: 0.5918\n",
      "Epoch: 32/80 Step: 450 Training Loss: 0.2035 Validation Loss: 0.5914\n",
      "Epoch: 36/80 Step: 500 Training Loss: 0.1649 Validation Loss: 0.5899\n",
      "Epoch: 40/80 Step: 550 Training Loss: 0.1351 Validation Loss: 0.5889\n",
      "Epoch: 44/80 Step: 600 Training Loss: 0.1211 Validation Loss: 0.5877\n",
      "Epoch: 48/80 Step: 650 Training Loss: 0.1038 Validation Loss: 0.5911\n",
      "Epoch: 52/80 Step: 700 Training Loss: 0.0900 Validation Loss: 0.5838\n",
      "Epoch: 56/80 Step: 750 Training Loss: 0.0781 Validation Loss: 0.5937\n",
      "Epoch: 60/80 Step: 800 Training Loss: 0.0659 Validation Loss: 0.5950\n",
      "Epoch: 64/80 Step: 850 Training Loss: 0.0618 Validation Loss: 0.5974\n",
      "Epoch: 68/80 Step: 900 Training Loss: 0.0549 Validation Loss: 0.5982\n",
      "Epoch: 72/80 Step: 950 Training Loss: 0.0503 Validation Loss: 0.6001\n",
      "Epoch: 76/80 Step: 1000 Training Loss: 0.0433 Validation Loss: 0.5983\n",
      "Epoch: 80/80 Step: 1050 Training Loss: 0.0400 Validation Loss: 0.6049\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "n_epochs = 80\n",
    "clip = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        #To prevent exploding gradients\n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < 0.02:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        if (step % 50) == 0:            \n",
    "            net.eval()\n",
    "            valid_losses = []\n",
    "            num_val_batch =0 \n",
    "            for v_inputs, v_labels in valid_loader:\n",
    "                num_val_batch += 1\n",
    "                v_inputs, v_labels = v_inputs.to(device), v_labels.to(device)\n",
    "\n",
    "                \n",
    "                v_output, v_h = net(v_inputs)\n",
    "                v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "                valid_losses.append(v_loss.item())\n",
    "               \n",
    "            valid_losses = sum(valid_losses)/len(valid_losses)\n",
    "                \n",
    "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "                  \"Step: {}\".format(step),\n",
    "                  \"Training Loss: {:.4f}\".format(loss.item()),\n",
    "                  \"Validation Loss: {:.4f}\".format(valid_losses),\n",
    "                 )\n",
    "\n",
    "            if valid_losses - loss.item() > 0.2:\n",
    "                break\n",
    "                \n",
    "            net.train()\n",
    "            \n",
    "#torch.save(net.state_dict(), \"LSTM.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6936292054402291\n",
      "1397\n",
      "1397\n"
     ]
    }
   ],
   "source": [
    "net.eval().to(device)\n",
    "count = 0\n",
    "sums = 0\n",
    "\n",
    "for v_inputs, v_labels in test_loader:\n",
    "    \n",
    "    sums = sums + len(v_inputs)\n",
    "    \n",
    "    v_inputs, v_labels = v_inputs.to(device), v_labels.to(device)\n",
    "\n",
    "    v_output, v_h = net(v_inputs)\n",
    "    \n",
    "    v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "        \n",
    "\n",
    "    output = torch.round(v_output.squeeze()).detach().cpu().numpy().astype(int)\n",
    "\n",
    "    ground = v_labels.detach().cpu().numpy().astype(int)\n",
    "\n",
    "    count = count + np.sum(output == ground)\n",
    "    \n",
    "print(\"Accuracy: \" + str(count/len(test_x)))\n",
    "print(len(test_x))\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(net, review, seq_length = 200):\n",
    "    device = \"cuda\" #\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    text = review.lower()\n",
    "    text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "    words = text\n",
    "    \n",
    "    encoded_train =tokenizer.texts_to_sequences([words])\n",
    "    padded_words = pad_text(encoded_train, seq_length = 200)\n",
    "    padded_words = torch.from_numpy(padded_words).to(device)\n",
    "\n",
    "    \n",
    "    net.eval().to(device)\n",
    "    output, h = net(padded_words )#, h)\n",
    "    pred = torch.round(output.squeeze())  \n",
    "    return pred\n",
    "\n",
    "Test = [\n",
    "    \"It make me happy\",\n",
    "    \"Unpleasant viewing experience\",\n",
    "    \"I am interested with this assigment\",\n",
    "    \"Poor you\",\n",
    "    \"Happy new year\"\n",
    "]\n",
    "for t in Test:\n",
    "    lab = inference(net, t).tolist()\n",
    "    if int(lab) == 0:\n",
    "        print(\"negative:\\t\"+t)\n",
    "    else:\n",
    "        print(\"postive:\\t\"+t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taco",
   "language": "python",
   "name": "taco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
