{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sys\n",
    "import os\n",
    "import string, nltk\n",
    "#nltk.download('stopwords')\n",
    "nltk.data.path.append(\"/home/ubuntu/nltk_data\")\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "import numpy as np\n",
    "import torch\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchsummary import summary\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = pd.read_csv('glove.6B.300d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove_embedding = {key: val.values for key, val in glove.T.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocab = []\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english') + list(string.punctuation)) \n",
    "\n",
    "def create_embedding_matrix(word_index,embedding_dict,dimension):\n",
    "    embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
    "\n",
    "    for word,index in word_index.items():\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[index]=embedding_dict[word]\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def Norm(text,wordnet_lemmatizer,stop_words):\n",
    "    text = text.lower().replace(\"\\s+\",\" \")\n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            w = wordnet_lemmatizer.lemmatize(w, pos=\"v\")\n",
    "            filtered_sentence.append(w) \n",
    "    texts=\" \".join(str(x) for x in filtered_sentence)\n",
    "    return text\n",
    "\n",
    "def pad_text(encoded_reviews, seq_length):\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in encoded_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append([0]*(seq_length-len(review)) + review)\n",
    "        \n",
    "    return np.array(reviews)\n",
    "\n",
    "def LoadData(file, Vocab=Vocab):\n",
    "    with open(file, \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        contents = f.read().splitlines()\n",
    "        for line in contents:\n",
    "            try:\n",
    "                _,text,label = line.split(\"#\")\n",
    "            except:\n",
    "                continue\n",
    "            text = text.split(\" \",1)[1]\n",
    "            \n",
    "            text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "            text = Norm(text,wordnet_lemmatizer,stop_words)\n",
    "            \n",
    "            data_x.append(text)\n",
    "            data_y.append(label)\n",
    "            Vocab = Vocab + text.split(\" \")\n",
    "        return data_x, data_y, Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e975234c77fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdev_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mencoded_train\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_v' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_x, train_y, Vocab = LoadData(\"../data/train.txt\",Vocab)\n",
    "dev_x, dev_y, Vocab = LoadData(\"../data/dev.txt\",Vocab)\n",
    "test_x, test_y, Vocab = LoadData(\"../data/test.txt\",Vocab)\n",
    "\n",
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
    "tokenizer.fit_on_texts(train_x+dev_x+test_v)\n",
    "\n",
    "encoded_train =tokenizer.texts_to_sequences(train_x)\n",
    "encoded_dev =tokenizer.texts_to_sequences(dev_x)\n",
    "encoded_test =tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "\n",
    "train_x = pad_text(encoded_train, seq_length = 200)\n",
    "train_y = np.array([1 if label == \"pos\" else 0 for label in train_y])\n",
    "\n",
    "\n",
    "dev_x = pad_text(encoded_dev, seq_length = 200)\n",
    "dev_y = np.array([1 if label == \"pos\" else 0 for label in dev_y])\n",
    "\n",
    "\n",
    "test_x = pad_text(encoded_test, seq_length = 200)\n",
    "test_y = np.array([1 if label == \"pos\" else 0 for label in test_y])\n",
    "\n",
    "\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(dev_x), torch.from_numpy(dev_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding_matrix=create_embedding_matrix(tokenizer.word_index,embedding_dict=glove_embedding,dimension=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class NetworkLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.embedding.weight=torch.nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
    "        \n",
    "        self.lstm = nn.LSTM(n_embed, hidden_node, layers, batch_first = True, bidirectional=False)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):                       # => batch size, sent len\n",
    "        embedded_words = self.embedding(input_words)    # => (batch_size, seq_length, n_embed)\n",
    "        lstm_out, hidden = self.lstm(embedded_words)         # =>  (batch_size, seq_length, n_hidden)\n",
    "        \n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, hidden\n",
    "\n",
    "class NetworkLSTM_(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Wir = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Whr = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.Wif = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Whf = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.Wig = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Whg = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.Wio = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Who = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.hidden_node = hidden_node\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward (self, input_words):                    # => (batch size, sent len)\n",
    "        \n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "        embedded_words = embedded_words.permute(1,0,2)   #  (seq_length,batch_size,  n_embed)\n",
    "        hidden = torch.zeros(input_words.size(0), self.hidden_node).to(device)  # batch-node\n",
    "        \n",
    "        c = torch.zeros(input_words.size(0), self.hidden_node).to(device)\n",
    "        \n",
    "        for i in range(input_words.size(1)):           #for i in seq_length\n",
    "\n",
    "            ir=embedded_words[i].matmul(self.Wir)\n",
    "            hr=hidden.matmul(   self.Whr)\n",
    "            r= ir.add(hr)\n",
    "            rt = self.sigmoid(r)\n",
    "            \n",
    "            iff=embedded_words[i].matmul(self.Wif)\n",
    "            hff=hidden.matmul(   self.Whf)\n",
    "            ff= iff.add(hff)\n",
    "            fft = self.sigmoid(ff)\n",
    "            \n",
    "            ig=embedded_words[i].matmul(self.Wig)\n",
    "            hg=hidden.matmul(   self.Whg)\n",
    "            g= ig.add(hg)\n",
    "            gt = self.tanh(g)\n",
    "            \n",
    "            io=embedded_words[i].matmul(self.Wio)\n",
    "            ho=hidden.matmul(   self.Who)\n",
    "            o= io.add(ho)\n",
    "            ot = self.sigmoid(o)\n",
    "            \n",
    "            c = fft*c + rt*gt\n",
    "            hidden = ot*self.tanh(c)\n",
    "        \n",
    "        out = self.fc(hidden)\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, hidden\n",
    "    \n",
    "class NetworkGRU_(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Wir = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Whr = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.Wiz = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Whz = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.Win = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Whn = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.hidden_node = hidden_node\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward (self, input_words):                    # => (batch size, sent len)\n",
    "        \n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "        embedded_words = embedded_words.permute(1,0,2)   #  (seq_length,batch_size,  n_embed)\n",
    "        hidden = torch.zeros(input_words.size(0), self.hidden_node).to(device)  # batch-node\n",
    "        \n",
    "        for i in range(input_words.size(1)):           #for i in seq_length\n",
    "\n",
    "            ir=embedded_words[i].matmul(self.Wir)\n",
    "            hr=hidden.matmul(   self.Whr)\n",
    "            r= ir.add(hr)\n",
    "            rt = self.sigmoid(r)\n",
    "            \n",
    "            #print(rt.shape)\n",
    "            \n",
    "            iz=embedded_words[i].matmul(self.Wiz)\n",
    "            hz=hidden.matmul(   self.Whz)\n",
    "            z= iz.add(hz)\n",
    "            zt = self.sigmoid(z)\n",
    "            \n",
    "            iN=embedded_words[i].matmul(self.Win)\n",
    "            hN=hidden.matmul(   self.Whz)*rt\n",
    "            N= iN.add(hN)\n",
    "            Nt = self.tanh(N)\n",
    "            \n",
    "            hidden = (1-zt)*Nt + zt*hidden\n",
    "        \n",
    "        out = self.fc(hidden)\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, hidden\n",
    "    \n",
    "class NetworkRNN_(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Wi = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "        self.Wh = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "        self.hidden_node = hidden_node\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "#         self.rnn = nn.RNN(n_embed, hidden_node, layers, batch_first = True, bidirectional=False)\n",
    "#         self.rnn_cell = nn.RNNCell(n_embed, hidden_node)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward (self, input_words):                    # => (batch size, sent len)\n",
    "        \n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "        embedded_words = embedded_words.permute(1,0,2)   #  (seq_length,batch_size,  n_embed)\n",
    "        hidden = torch.zeros(input_words.size(0), self.hidden_node).to(device)  # batch-node\n",
    "        \n",
    "        for i in range(input_words.size(1)):           #for i in seq_length\n",
    "\n",
    "            A=embedded_words[i].matmul(self.Wi)\n",
    "            B=hidden.matmul(   self.Wh)\n",
    "            C = A.add(B)\n",
    "            hidden = self.sigmoid(C)\n",
    "        \n",
    "        out = self.fc(hidden)\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, hidden\n",
    "    \n",
    "class NetworkGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        \n",
    "        self.gru = nn.GRU(n_embed, hidden_node, layers, batch_first = True, bidirectional=False)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):\n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "        gru_out, hidden = self.gru(embedded_words)         # (batch_size, seq_length, n_hidden)\n",
    "        \n",
    "        out = self.fc(gru_out[:, -1, :])\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, hidden\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class NetworkRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        \n",
    "        self.rnn = nn.RNN(n_embed, hidden_node, layers, batch_first = True, bidirectional=False)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):\n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "        gru_out, hidden = self.rnn(embedded_words)         # (batch_size, seq_length, n_hidden)\n",
    "        \n",
    "        out = self.fc(gru_out[:, -1, :])\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_vocab=embedding_matrix.shape[0]\n",
    "n_embed=embedding_matrix.shape[1]\n",
    "n_hidden = 256 #512\n",
    "n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\n",
    "layers = 1\n",
    "\n",
    "net = NetworkLSTM(n_vocab, n_embed, n_hidden, n_output, layers).cuda()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "criterion = criterion.cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "print(net)\n",
    "\n",
    "# inp = torch.zeros((1,200), dtype=torch.long) # [length, batch_size]\n",
    "# print(summary(net,(300) ))\n",
    "\n",
    "print_every = 100\n",
    "step = 0\n",
    "n_epochs = 8 #4\n",
    "clip = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs)\n",
    "        try:\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "        except:\n",
    "            output[output < 0.0] = 0.0\n",
    "            output[output > 1.0] = 1.0\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (step % print_every) == 0:            \n",
    "            net.eval()\n",
    "            valid_losses = []\n",
    "            \n",
    "            for v_inputs, v_labels in valid_loader:\n",
    "                v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                \n",
    "                v_output, v_h = net(v_inputs)\n",
    "                v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "                valid_losses.append(v_loss.item())\n",
    "\n",
    "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "                  \"Step: {}\".format(step),\n",
    "                  \"Training Loss: {:.4f}\".format(loss.item()),\n",
    "                  \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
    "            net.train()\n",
    "            \n",
    "torch.save(net.state_dict(), \"LSTM.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# \n",
    "\n",
    "def inference(net, review, seq_length = 200):\n",
    "    device = \"cuda\" #\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    text = review.lower()\n",
    "    text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "    words = text\n",
    "    \n",
    "    encoded_words = [vocab_to_int[word] for word in words.split(\" \")]\n",
    "    padded_words = pad_text([encoded_words], seq_length)\n",
    "    padded_words = torch.from_numpy(padded_words).to(device)\n",
    "\n",
    "    \n",
    "    net.eval().to(device)\n",
    "    output, h = net(padded_words )#, h)\n",
    "    pred = torch.round(output.squeeze())  \n",
    "    return pred\n",
    "\n",
    "\n",
    "inference(net, \"I am sad\") \n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval().to(device)\n",
    "count = 0\n",
    "for v_inputs, v_labels in test_loader:\n",
    "    v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    v_output, v_h = net(v_inputs)\n",
    "\n",
    "    output = torch.round(v_output.squeeze()).detach().cpu().numpy().astype(int)\n",
    "    #print(len(output))\n",
    "    ground = labels.detach().cpu().numpy().astype(int)\n",
    "    #print(len(ground))\n",
    "    count = count + np.sum(output == ground)\n",
    "print(count/len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(checkpoint, test_file, Vocab):\n",
    "\n",
    "    #     n_vocab = len(vocab_to_int)\n",
    "#     n_embed = 400\n",
    "#     n_hidden = 512\n",
    "#     n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\n",
    "#     layers = 1\n",
    "\n",
    "#     net = NetworkRNN(n_vocab, n_embed, n_hidden, n_output, layers).cuda()\n",
    "    \n",
    "#     test_x, test_y, Vocab = LoadData(\"../data/test.txt\",Vocab)\n",
    "\n",
    "#     net.load_state_dict(torch.load(\"LSTM.pt\"))\n",
    "    \n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    net.eval().to(device)\n",
    "    count = 0\n",
    "    for v_inputs, v_labels in test_loader:\n",
    "        v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        v_output, v_h = net(v_inputs)\n",
    "\n",
    "        output = torch.round(v_output.squeeze()).detach().cpu().numpy().astype(int)\n",
    "        #print(len(output))\n",
    "        ground = labels.detach().cpu().numpy().astype(int)\n",
    "        #print(len(ground))\n",
    "        count = count + np.sum(output == ground)\n",
    "    print(count/len(test_x))\n",
    "\n",
    "\n",
    "# In[162]:\n",
    "\n",
    "\n",
    "predict(\"LSTM.pt\",\"../data/test.txt\",Vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taco",
   "language": "python",
   "name": "taco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
