{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Cuda Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sys\n",
    "import os\n",
    "import string, nltk\n",
    "#nltk.download('stopwords')\n",
    "nltk.data.path.append(\"/home/ubuntu/nltk_data\")\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "import numpy as np\n",
    "import torch\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn, optim\n",
    "#from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Global variable and Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pretrain Embedding from Glove, at this report, I use two pretrain glove with 100 and 300 dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqence_len = 100\n",
    "embed_len = 300\n",
    "Vocab = []\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english') + list(string.punctuation)) \n",
    "\n",
    "glove = pd.read_csv('glove.6B.'+str(embed_len)+'d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove_embedding = {key: val.values for key, val in glove.T.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Embedding matrix from pretrain\n",
    "- By using pretrain Glove, for each word, we map it to a representative vector\n",
    "\n",
    "Normalization the input text:\n",
    "- All  stopwords  and  punctuations  are  filter  out\n",
    "- With  lemmatization,  a  word  returns  an  actual  word  of  thelanguage. It reduces the inflected words properly ensuring thatthe  root  word  belongs  to  the  language\n",
    "\n",
    "Padding Text\n",
    "- To let all input sentences have the same length, so that we can train in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_index,embedding_dict,dimension):\n",
    "    embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
    "\n",
    "    for word,index in word_index.items():\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[index]=embedding_dict[word]\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def Norm(text,wordnet_lemmatizer,stop_words):\n",
    "    text = text.lower().strip()\n",
    "    text =  re.sub(' +', ' ', text)\n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            w = wordnet_lemmatizer.lemmatize(w, pos=\"v\")\n",
    "            filtered_sentence.append(w) \n",
    "    texts=\" \".join(str(x) for x in filtered_sentence)\n",
    "    return text\n",
    "\n",
    "def pad_text(encoded_reviews, seq_length):\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in encoded_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append([0]*(seq_length-len(review)) + review)\n",
    "        \n",
    "    return np.array(reviews)\n",
    "\n",
    "def LoadData(file, Vocab=Vocab):\n",
    "    with open(file, \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        contents = f.read().splitlines()\n",
    "        for line in contents:\n",
    "            try:\n",
    "                _,text,label = line.split(\"#\")\n",
    "            except:\n",
    "                continue\n",
    "            text = text.split(\" \",1)[1]\n",
    "            \n",
    "            text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "            text = Norm(text,wordnet_lemmatizer,stop_words)\n",
    "            \n",
    "            data_x.append(text)\n",
    "            data_y.append(label)\n",
    "            Vocab = Vocab + text.split(\" \")\n",
    "        return data_x, data_y, Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sandra bullock and hugh grant make a great team but this predictable romantic comedy should get a pink slip', 'those eternally devoted to the insanity of black will have an intermittently good time feel free to go get popcorn whenever hes not onscreen', 'this is wild surreal stuff but brilliant and the camera just kind of sits there and lets you look at this and its like youre going from one room to the next and none of them have any relation to the other', 'this is a harrowing movie about how parents know where all the buttons are and how to push them', 'without shakespeares eloquent language the update is dreary and sluggish']\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, Vocab = LoadData(\"../data/train.txt\",Vocab)\n",
    "dev_x, dev_y, Vocab = LoadData(\"../data/dev.txt\",Vocab)\n",
    "test_x, test_y, Vocab = LoadData(\"../data/test.txt\",Vocab)\n",
    "print(test_x[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenght of sentences distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  0.,  0.,  0.,  3.,  2.,  0.,  3.,  2.,  1.,  2., 11.,\n",
       "        10., 13., 15., 11., 15., 12., 18., 19., 18., 24., 29., 20., 28.,\n",
       "        29., 27., 25., 23., 27., 29., 25., 16., 31., 24., 28., 27., 28.,\n",
       "        39., 33., 36., 29., 37., 38., 46., 42., 38., 41., 37., 48., 48.,\n",
       "        35., 56., 35., 49., 56., 38., 40., 43., 39., 47., 47., 56., 44.,\n",
       "        46., 50., 53., 39., 42., 44., 38., 57., 53., 64., 50., 57., 52.,\n",
       "        52., 53., 50., 65., 59., 58., 53., 64., 54., 58., 69., 64., 45.,\n",
       "        70., 74., 57., 49., 59., 53., 48., 54., 55., 73., 64., 68., 49.,\n",
       "        70., 52., 78., 55., 45., 45., 52., 61., 52., 56., 60., 65., 66.,\n",
       "        61., 55., 53., 65., 60., 51., 54., 49., 58., 54., 48., 58., 54.,\n",
       "        53., 37., 53., 36., 46., 53., 52., 41., 42., 45., 44., 52., 60.,\n",
       "        37., 53., 43., 38., 37., 43., 42., 45., 46., 35., 42., 38., 33.,\n",
       "        44., 34., 38., 39., 37., 36., 38., 39., 21., 33., 47., 34., 14.,\n",
       "        20., 23., 22., 34., 26., 19., 21., 22., 19., 22., 21., 20., 16.,\n",
       "        16., 22., 15., 12., 16., 17., 12., 16., 19., 19.,  8.,  8., 11.,\n",
       "        15., 17., 27.]),\n",
       " array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "        196, 197, 198, 199]),\n",
       " <BarContainer object of 198 artists>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAATM0lEQVR4nO3dfYxl913f8fcHO+bBPNiOp6utnWU2xARZSHHckWuUELVZhzoJzS4lshyhsoClVSWgpAHB0kiFVv3D7gMhSKh0iVOWKiQOJtausAoxSwBVgoW1s4ntOK7XZg1erXeXxE5CqQCHb/+4Z8nd8Z2ZMzP36Tfzfkmje87vnjv3u+ee+ezv/M7DTVUhSWrPV826AEnSxhjgktQoA1ySGmWAS1KjDHBJatTl03yza6+9thYXF6f5lpLUvIcffvgvqmpheftUA3xxcZETJ05M8y0lqXlJnh3V3msIJcm/SfJ4kseSfDjJ1yTZneR4klNJ7ktyxXhLliStZs0AT3Id8K+Bpar6duAy4E7gHuB9VfUa4AXgrkkWKkm6VN+DmJcDX5vkcuDrgLPAm4H7u+cPA/vGXp0kaUVrBnhVnQH+C/BnDIL7C8DDwItV9VK32HPAdaNen+RAkhNJTly4cGE8VUuSeg2hXA3sBXYD/xC4Eri97xtU1aGqWqqqpYWFlx1ElSRtUJ8hlNuAP62qC1X1t8DHgDcAV3VDKgDXA2cmVKMkaYQ+Af5nwK1Jvi5JgD3AZ4BPAO/sltkPHJlMiZKkUfqMgR9ncLDyEeDR7jWHgJ8C3pPkFPBK4N4J1ilJWqbXhTxV9TPAzyxrfga4ZewVSZJ68V4o0jotHnyQxYMPzroMyQCXpFYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeDasrxiUludAS5JjTLAJalRBrg0xCEXtcQAl6RGGeCS1CgDXJIaZYBLUqPWDPAkr01ycujni0neneSaJA8leap7vHoaBUuSBvp8qfGTVXVTVd0E/CPgr4AHgIPAsaq6ATjWzUuSpmS9Qyh7gKer6llgL3C4az8M7BtjXZKkNaw3wO8EPtxN76iqs93088COUS9IciDJiSQnLly4sMEypfUZ9/ncnh+uedQ7wJNcAbwD+PXlz1VVATXqdVV1qKqWqmppYWFhw4VKki61nh74W4FHqupcN38uyU6A7vH8uIuTJK1sPQH+Lr4yfAJwFNjfTe8HjoyrKGk9vOugtqteAZ7kSuAtwMeGmu8G3pLkKeC2bl6SNCW9Aryq/m9VvbKqvjDU9rmq2lNVN1TVbVX1+cmVKU2fvXrNO6/ElKRGGeCS1CgDXJIaZYBLUqMMcElqlAEuTZHnrGucDHBJapQBrrm11Xqqa/17ttq/V5NngEtSowxwSWqUAa6pGscwwUq/Y1xDEB5oVCsMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktSovl+pdlWS+5N8NskTSb4jyTVJHkryVPd49aSLlSR9Rd8e+PuB36qqbwNeBzwBHASOVdUNwLFuXtr2+pxD7nnmGoc1AzzJNwFvAu4FqKq/qaoXgb3A4W6xw8C+yZQoSRqlTw98N3AB+B9JPpnkA9231O+oqrPdMs8DOyZVpCTp5S7vuczNwI9W1fEk72fZcElVVZIa9eIkB4ADALt27dpkuVJ71jNccnHZ03e/fVLlzPX7a3369MCfA56rquPd/P0MAv1ckp0A3eP5US+uqkNVtVRVSwsLC+OoWZJEjwCvqueBP0/y2q5pD/AZ4Ciwv2vbDxyZSIXa1sZ9YylvVKWtpM8QCsCPAh9KcgXwDPCDDML/o0nuAp4F7phMiZKkUXoFeFWdBJZGPLVnrNVIknrzSkw1YdL3AJ93o4Z+tsu/XSszwCWpUQa4Jm7WvWcPXGqrMsAlqVEGuCQ1ygDfZkYdCOs7vOAwxPq5zjRJBrgkNcoAl6RGGeASGztTZbPDI54do80ywCWpUQa4mjTO3uu89oL7XH1pL357M8AlqVEGuCQ1ygDXpvXZjR/HMlt12GQc/67h14/6XRv5/Q7PzD8DXJIaZYBLUqP6fiOPNBEt7aL3GQLqu+wsrPWFxfNYs1ZnD1ySGtWrB57kNPAl4MvAS1W1lOQa4D5gETgN3FFVL0ymTGl7sTesPtbTA/+nVXVTVV38bsyDwLGqugE41s1LkqZkM0Moe4HD3fRhYN+mq5Ek9db3IGYBH09SwH+vqkPAjqo62z3/PLBj1AuTHAAOAOzatWuT5WqebHQ3fz0HAyWtrG+Av7GqziT5B8BDST47/GRVVRfuL9OF/SGApaWlkctIktav1xBKVZ3pHs8DDwC3AOeS7AToHs9PqkhJ0sut2QNPciXwVVX1pW76u4D/ABwF9gN3d49HJlmoxm+7DVVs9HLyWZuHGjSf+gyh7AAeSHJx+V+rqt9K8ifAR5PcBTwL3DG5MiVJy60Z4FX1DPC6Ee2fA/ZMoiiNx3DPbaWr77azVnu2rdat8fNKTElqlAEuSY3yZlZalbvrmrW1bsK1ndkDl6RGGeCS1CiHUBo2y11Lh1baMK3PyWGO2bAHLkmNsgeuLWXaewat74ksHnxw073m1tdBy+yBS1KjDHBJapQBrnVZPPhgr11md6vb0fcz3ex7aPwMcElqlAEuSY0ywPUy7u5q2KjtwW1kPhjgktQozwPfAsZxLu+42DNrwzg+p5V+h1dlTo89cElqVO8AT3JZkk8m+c1ufneS40lOJbkvyRWTK1OStNx6euA/BjwxNH8P8L6qeg3wAnDXOAvTxjiEobW4jWwdvQI8yfXA24EPdPMB3gzc3y1yGNg3gfokSSvo2wP/eeAngb/r5l8JvFhVL3XzzwHXjbc0SdJq1jwLJcl3A+er6uEk/2S9b5DkAHAAYNeuXet9uabIXWupLX164G8A3pHkNPARBkMn7weuSnLxP4DrgTOjXlxVh6pqqaqWFhYWxlCyJAl6BHhV/XRVXV9Vi8CdwO9W1fcBnwDe2S22HzgysSq3oWncYGjc728PXn2ttn25HfW3mfPAfwp4T5JTDMbE7x1PSZKkPtZ1JWZV/R7we930M8At4y9JktSHl9I3avlu5mZ3Oyex2+qu8NaxkcvjV7rFg0Mn4+Ol9JLUKANckhrlEEpj/DozrWScn/u0hjm8c+Hm2AOXpEbZA2+AvRStV2t7Ya3VOy/sgUtSowxwSWqUQyjbxPAuqrurmhS3remyBy5JjTLAJalRBrikqdjsHTZXe+2s7945Kwa4JDXKg5hzbjv2KrR1zONN1rYSe+CS1CgDXJIaZYBLUqMMcElq1JoBnuRrkvxxkk8leTzJv+/adyc5nuRUkvuSXDH5creO7Xrak6Tx6dMD/2vgzVX1OuAm4PYktwL3AO+rqtcALwB3TaxKSdLLrBngNfCX3ewrup8C3gzc37UfBvZNokBJ0mi9xsCTXJbkJHAeeAh4Gnixql7qFnkOuG6F1x5IciLJiQsXLoyhZEkS9AzwqvpyVd0EXA/cAnxb3zeoqkNVtVRVSwsLCxurUpL0Mus6C6WqXgQ+AXwHcFWSi1dyXg+cGW9pkqTV9DkLZSHJVd301wJvAZ5gEOTv7BbbDxyZUI1zZ9QZJGudVTKOM048a0XSsD73QtkJHE5yGYPA/2hV/WaSzwAfSfIfgU8C906wTknSMmsGeFV9Gnj9iPZnGIyHb2vj7Fmfvvvt9rIl9eaVmJLUKANckhplgI/Zeg9urvZaSe2b5N+1AS5JjTLAJalRBrikLWO73eXTAJekRhngE7BSL2C79Q4kTZYBLkmNMsAlqVEG+DqNewjEIRVJG2WAS1KjDHBJapQBPkEOj0iT41ldBrgkNcsAl9S0tXrhw8+v9a1ZrfXoDXBJapQBLkmNWvMr1ZK8CvhVYAdQwKGqen+Sa4D7gEXgNHBHVb0wuVIlbReT/BLw4a8wbF2fHvhLwI9X1Y3ArcAPJ7kROAgcq6obgGPdvCRpStYM8Ko6W1WPdNNfAp4ArgP2Aoe7xQ4D+yZUoyRphHWNgSdZZPAN9ceBHVV1tnvqeQZDLKNecyDJiSQnLly4sJla505rR6ylrWKSQywt6R3gSb4e+A3g3VX1xeHnqqoYjI+/TFUdqqqlqlpaWFjYVLGSpK9Y8yAmQJJXMAjvD1XVx7rmc0l2VtXZJDuB85MqctYWDz64JQ54SNvFqC8Xn9Tvn2U2rNkDTxLgXuCJqvq5oaeOAvu76f3AkfGXJ0laSZ8e+BuAfwk8muRk1/ZvgbuBjya5C3gWuGMiFUqSRlozwKvqfwNZ4ek94y1nvvS9BFeSZsErMSWpUQa4JDWq11kokrRdbfTS+2kMu9oDl6RG2QOfAQ+ISvNhPfcS7/uaabIHLkmNMsAlqVEGOJd+lVKLX6skaXxaulGWAS5JjTLAJalRnoUiqRkOb17KHrgkNWrbB7j/o0tq1bYPcElqlQEuSY3yIOYKHFqRtq95v4T+InvgktSoPt+J+cEk55M8NtR2TZKHkjzVPV492TIlScv16YH/CnD7sraDwLGqugE41s03YbVL5edxF0lSO6Z9K441A7yq/gD4/LLmvcDhbvowsG+8ZUmS1rLRg5g7qupsN/08sGOlBZMcAA4A7Nq1a4NvN372tiW1btMHMauqgFrl+UNVtVRVSwsLC5t9O0lSZ6MBfi7JToDu8fz4SpIk9bHRAD8K7O+m9wNHxlOOJKmvPqcRfhj4Q+C1SZ5LchdwN/CWJE8Bt3XzkqQpWvMgZlW9a4Wn9oy5FknSOngpvSRtwizPaPNSeklqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1assE+PIbykz7y0Uladq2TIBL0nazpQJ8VK97eN4euaStZEsFuCRtJwa4JDVqUwGe5PYkTyY5leTguIpazUaGQTygKWkr2nCAJ7kM+EXgrcCNwLuS3DiuwiRJq9tMD/wW4FRVPVNVfwN8BNg7nrIkSWvZzJcaXwf8+dD8c8A/Xr5QkgPAgW72L5M8uYH3uhb4i7//nfesvvBaz4/RJXXNkXmtC+a3tnmtC+a3tnmtC+astqFM2mhd3zyqceLfSl9Vh4BDm/kdSU5U1dKYShob61q/ea1tXuuC+a1tXuuC+a1t3HVtZgjlDPCqofnruzZJ0hRsJsD/BLghye4kVwB3AkfHU5YkaS0bHkKpqpeS/Ajw28BlwAer6vGxVXapTQ3BTJB1rd+81javdcH81javdcH81jbWulJV4/x9kqQp8UpMSWqUAS5JjZrrAJ/Fpfor1PGqJJ9I8pkkjyf5sa79Z5OcSXKy+3nbjOo7neTRroYTXds1SR5K8lT3ePWUa3rt0Ho5meSLSd49q3WW5INJzid5bKht5DrKwC90292nk9w85br+c5LPdu/9QJKruvbFJP9vaN390qTqWqW2FT+/JD/drbMnk/yzKdd131BNp5Oc7Nqnts5WyYnJbWdVNZc/DA6MPg28GrgC+BRw44xq2Qnc3E1/A/B/GNw+4GeBn5iDdXUauHZZ238CDnbTB4F7ZvxZPs/gYoSZrDPgTcDNwGNrrSPgbcD/AgLcChyfcl3fBVzeTd8zVNfi8HIzWmcjP7/u7+FTwFcDu7u/3cumVdey5/8r8O+mvc5WyYmJbWfz3AOfm0v1q+psVT3STX8JeILBlajzbC9wuJs+DOybXSnsAZ6uqmdnVUBV/QHw+WXNK62jvcCv1sAfAVcl2Tmtuqrq41X1Ujf7RwyusZi6FdbZSvYCH6mqv66qPwVOMfgbnmpdSQLcAXx4Eu+9mlVyYmLb2TwH+KhL9WcemkkWgdcDx7umH+l2fz447WGKIQV8PMnDGdy6AGBHVZ3tpp8HdsymNGBwjcDwH9Q8rDNYeR3N07b3Qwx6aRftTvLJJL+f5DtnVNOoz29e1tl3Aueq6qmhtqmvs2U5MbHtbJ4DfO4k+XrgN4B3V9UXgf8GfAtwE3CWwa7bLLyxqm5mcGfIH07ypuEna7C/NpPzRTO4yOsdwK93TfOyzi4xy3W0kiTvBV4CPtQ1nQV2VdXrgfcAv5bkG6dc1lx+fkPexaWdhamvsxE58ffGvZ3Nc4DP1aX6SV7B4EP5UFV9DKCqzlXVl6vq74BfZkK7jGupqjPd43ngga6Ocxd3x7rH87OojcF/Ko9U1bmuxrlYZ52V1tHMt70kPwB8N/B93R893fDE57rphxmMM3/rNOta5fObh3V2OfAvgPsutk17nY3KCSa4nc1zgM/NpfrduNq9wBNV9XND7cPjVd8DPLb8tVOo7cok33BxmsEBsMcYrKv93WL7gSPTrq1zSY9oHtbZkJXW0VHg+7uzBG4FvjC0CzxxSW4HfhJ4R1X91VD7Qgb34SfJq4EbgGemVVf3vit9fkeBO5N8dZLdXW1/PM3agNuAz1bVcxcbprnOVsoJJrmdTePo7CaO6r6NwZHcp4H3zrCONzLY7fk0cLL7eRvwP4FHu/ajwM4Z1PZqBkf/PwU8fnE9Aa8EjgFPAb8DXDOD2q4EPgd801DbTNYZg/9EzgJ/y2Cs8a6V1hGDswJ+sdvuHgWWplzXKQZjoxe3tV/qlv3e7jM+CTwC/PMZrLMVPz/gvd06exJ46zTr6tp/BfhXy5ad2jpbJScmtp15Kb0kNWqeh1AkSaswwCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1Kj/j/K08cQOgQ06wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Len_Sentences = [len(x) for x in train_x]\n",
    "binz = [x for x in range(1,200)]\n",
    "plt.hist(Len_Sentences, bins=binz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data, Setup Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this experiment, the data is random load for each batch, do not apply strategy same lenght sentences for each batch\n",
    "\n",
    "Base on the distribution, the squence_lenght is set to average 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
    "tokenizer.fit_on_texts(train_x+dev_x+test_x)\n",
    "\n",
    "encoded_train =tokenizer.texts_to_sequences(train_x)\n",
    "encoded_dev =tokenizer.texts_to_sequences(dev_x)\n",
    "encoded_test =tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "\n",
    "train_x = pad_text(encoded_train, seq_length = seqence_len)\n",
    "train_y = np.array([1 if label == \"pos\" else 0 for label in train_y])\n",
    "\n",
    "\n",
    "dev_x = pad_text(encoded_dev, seq_length = seqence_len)\n",
    "dev_y = np.array([1 if label == \"pos\" else 0 for label in dev_y])\n",
    "\n",
    "\n",
    "test_x = pad_text(encoded_test, seq_length = seqence_len)\n",
    "test_y = np.array([1 if label == \"pos\" else 0 for label in test_y])\n",
    "\n",
    "# print(len(type(encoded_test)))\n",
    "\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(dev_x), torch.from_numpy(dev_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Classes (Positive and Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3912.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        3919.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([698.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 699.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dev_y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([699.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 698.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding_matrix=create_embedding_matrix(tokenizer.word_index,embedding_dict=glove_embedding,dimension=embed_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_hidden_r = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_input_r = nn.Linear(n_embed, n_hidden)\n",
    "\n",
    "        self.linear_hidden_f = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_input_f = nn.Linear(n_embed, n_hidden)\n",
    "\n",
    "        self.linear_hidden_g = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_input_g = nn.Linear(n_embed, n_hidden)\n",
    "\n",
    "        self.linear_hidden_o = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_input_o = nn.Linear(n_embed, n_hidden)\n",
    "        \n",
    "        self.hidden_node = hidden_node\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward (self, input_words):                    # => (batch size, sent len)\n",
    "        \n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "        embedded_words = embedded_words.permute(1,0,2)   #  (seq_length,batch_size,  n_embed)\n",
    "        hidden = torch.zeros(input_words.size(0), self.hidden_node).to(device)  # batch-node\n",
    "        \n",
    "        c = torch.zeros(input_words.size(0), self.hidden_node).to(device)\n",
    "        \n",
    "        for i in range(input_words.size(1)):           #for i in seq_length\n",
    "\n",
    "            ir=self.linear_input_r(embedded_words[i])\n",
    "            hr=self.linear_hidden_r(hidden)\n",
    "            r= ir.add(hr)\n",
    "            rt = self.sigmoid(r)\n",
    "            \n",
    "            iff=self.linear_input_f(embedded_words[i])\n",
    "            hff=self.linear_hidden_f(hidden)\n",
    "            ff= iff.add(hff)\n",
    "            fft = self.sigmoid(ff)\n",
    "            \n",
    "            ig=self.linear_input_g(embedded_words[i])\n",
    "            hg=self.linear_hidden_g(hidden)\n",
    "            g= ig.add(hg)\n",
    "            gt = self.tanh(g)\n",
    "            \n",
    "            io=self.linear_input_o(embedded_words[i])\n",
    "            ho=self.linear_hidden_o(hidden)\n",
    "            o= io.add(ho)\n",
    "            ot = self.sigmoid(o)\n",
    "            \n",
    "            c = fft*c + rt*gt\n",
    "            hidden = ot*self.tanh(c)\n",
    "        \n",
    "        out = self.fc(hidden)\n",
    "        \n",
    "        sig = self.sigmoid(out)\n",
    "        return sig, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab=embedding_matrix.shape[0]\n",
    "n_embed=embedding_matrix.shape[1]\n",
    "n_hidden = 512\n",
    "n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\n",
    "layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetworkLSTM(\n",
      "  (embedding): Embedding(20451, 300)\n",
      "  (lstm): LSTM(300, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "========================================================================================================\n",
      "Layer (type:depth-idx)                   Kernel Shape     Output Shape     Param #          Mult-Adds\n",
      "========================================================================================================\n",
      "├─Embedding: 1-1                         [300, 20451]     [1, 100, 300]    6,135,300        6,135,300\n",
      "├─LSTM: 1-2                              --               [1, 100, 512]    1,667,072        1,662,976\n",
      "|    └─weight_ih_l0                      [2048, 300]\n",
      "|    └─weight_hh_l0                      [2048, 512]\n",
      "├─Dropout: 1-3                           --               [1, 100, 512]    --               --\n",
      "├─Linear: 1-4                            [512, 1]         [1, 1]           513              512\n",
      "├─Sigmoid: 1-5                           --               [1, 1]           --               --\n",
      "========================================================================================================\n",
      "Total params: 7,802,885\n",
      "Trainable params: 7,802,885\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.80\n",
      "========================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.65\n",
      "Params size (MB): 31.21\n",
      "Estimated Total Size (MB): 31.86\n",
      "========================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "========================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape     Output Shape     Param #          Mult-Adds\n",
       "========================================================================================================\n",
       "├─Embedding: 1-1                         [300, 20451]     [1, 100, 300]    6,135,300        6,135,300\n",
       "├─LSTM: 1-2                              --               [1, 100, 512]    1,667,072        1,662,976\n",
       "|    └─weight_ih_l0                      [2048, 300]\n",
       "|    └─weight_hh_l0                      [2048, 512]\n",
       "├─Dropout: 1-3                           --               [1, 100, 512]    --               --\n",
       "├─Linear: 1-4                            [512, 1]         [1, 1]           513              512\n",
       "├─Sigmoid: 1-5                           --               [1, 1]           --               --\n",
       "========================================================================================================\n",
       "Total params: 7,802,885\n",
       "Trainable params: 7,802,885\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 7.80\n",
       "========================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.65\n",
       "Params size (MB): 31.21\n",
       "Estimated Total Size (MB): 31.86\n",
       "========================================================================================================"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NetworkLSTM(n_vocab, n_embed, n_hidden, n_output, layers).cuda()\n",
    "criterion = nn.BCELoss()\n",
    "criterion = criterion.cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "print(net)\n",
    "\n",
    "summary(\n",
    "    net,\n",
    "    (1, seqence_len),\n",
    "    dtypes=[torch.long],\n",
    "    verbose=2,\n",
    "    col_width=16,\n",
    "    col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/taco/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4 Step: 50 Training Loss: 0.5684\n",
      "Epoch: 1/4 Step: 100 Training Loss: 0.5152\n",
      "Epoch: 1/4 Step: 150 Training Loss: 0.4397\n",
      "Epoch: 2/4 Step: 200 Training Loss: 0.3760\n",
      "Epoch: 2/4 Step: 250 Training Loss: 0.2065\n",
      "Epoch: 2/4 Step: 300 Training Loss: 0.3702\n",
      "Epoch: 3/4 Step: 350 Training Loss: 0.2232\n",
      "Epoch: 3/4 Step: 400 Training Loss: 0.1328\n",
      "Epoch: 3/4 Step: 450 Training Loss: 0.2564\n",
      "Epoch: 4/4 Step: 500 Training Loss: 0.0479\n",
      "Epoch: 4/4 Step: 550 Training Loss: 0.1055\n",
      "Epoch: 4/4 Step: 600 Training Loss: 0.0548\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "n_epochs = 4\n",
    "clip = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs)\n",
    "        try:\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "        except:\n",
    "            output[output < 0.0] = 0.0\n",
    "            output[output > 1.0] = 1.0\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        #To prevent exploding gradients\n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (step % 50) == 0:            \n",
    "            net.eval()\n",
    "            valid_losses = []\n",
    "            \n",
    "            for v_inputs, v_labels in valid_loader:\n",
    "                v_inputs, v_labels = v_inputs.to(device), v_labels.to(device)\n",
    "\n",
    "                \n",
    "                v_output, v_h = net(v_inputs)\n",
    "                v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "                valid_losses.append(v_loss.item())\n",
    "                \n",
    "                \n",
    "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "                  \"Step: {}\".format(step),\n",
    "                  \"Training Loss: {:.4f}\".format(loss.item()))\n",
    "\n",
    "            \n",
    "            net.train()\n",
    "            \n",
    "#torch.save(net.state_dict(), \"LSTM.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7802433786685755\n",
      "1397\n",
      "1397\n"
     ]
    }
   ],
   "source": [
    "net.eval().to(device)\n",
    "count = 0\n",
    "sums = 0\n",
    "\n",
    "for v_inputs, v_labels in test_loader:\n",
    "    \n",
    "    sums = sums + len(v_inputs)\n",
    "    \n",
    "    v_inputs, v_labels = v_inputs.to(device), v_labels.to(device)\n",
    "\n",
    "    v_output, v_h = net(v_inputs)\n",
    "    \n",
    "    v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "        \n",
    "\n",
    "    output = torch.round(v_output.squeeze()).detach().cpu().numpy().astype(int)\n",
    "\n",
    "    ground = v_labels.detach().cpu().numpy().astype(int)\n",
    "\n",
    "    count = count + np.sum(output == ground)\n",
    "    \n",
    "print(\"Accuracy: \" + str(count/len(test_x)))\n",
    "print(len(test_x))\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postive:\tIt make me happy\n",
      "negative:\tUnpleasant viewing experience\n",
      "postive:\tI am interested with this assigment\n",
      "postive:\tPoor you\n",
      "postive:\tHappy new year\n"
     ]
    }
   ],
   "source": [
    "def inference(net, review, seq_length = 200):\n",
    "    device = \"cuda\" #\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    text = review.lower()\n",
    "    text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "    words = text\n",
    "    \n",
    "    encoded_train =tokenizer.texts_to_sequences([words])\n",
    "    padded_words = pad_text(encoded_train, seq_length = 200)\n",
    "    padded_words = torch.from_numpy(padded_words).to(device)\n",
    "\n",
    "    \n",
    "    net.eval().to(device)\n",
    "    output, h = net(padded_words )#, h)\n",
    "    pred = torch.round(output.squeeze())  \n",
    "    return pred\n",
    "\n",
    "Test = [\n",
    "    \"It make me happy\",\n",
    "    \"Unpleasant viewing experience\",\n",
    "    \"I am interested with this assigment\",\n",
    "    \"Poor you\",\n",
    "    \"Happy new year\"\n",
    "]\n",
    "for t in Test:\n",
    "    lab = inference(net, t).tolist()\n",
    "    if int(lab) == 0:\n",
    "        print(\"negative:\\t\"+t)\n",
    "    else:\n",
    "        print(\"postive:\\t\"+t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NetworkLSTM_(nn.Module):\n",
    "    \n",
    "#     def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.Wir = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "#         self.Whr = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "#         self.Wif = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "#         self.Whf = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "#         self.Wig = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "#         self.Whg = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "#         self.Wio = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "#         self.Who = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "#         self.hidden_node = hidden_node\n",
    "#         self.layers = layers\n",
    "        \n",
    "#         self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "#         self.fc = nn.Linear(n_hidden, n_output)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.tanh = nn.Tanh()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "#     def forward (self, input_words):                    # => (batch size, sent len)\n",
    "        \n",
    "#         embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "#         embedded_words = embedded_words.permute(1,0,2)   #  (seq_length,batch_size,  n_embed)\n",
    "#         hidden = torch.zeros(input_words.size(0), self.hidden_node).to(device)  # batch-node\n",
    "        \n",
    "#         c = torch.zeros(input_words.size(0), self.hidden_node).to(device)\n",
    "        \n",
    "#         for i in range(input_words.size(1)):           #for i in seq_length\n",
    "\n",
    "#             ir=embedded_words[i].matmul(self.Wir)\n",
    "#             hr=hidden.matmul(   self.Whr)\n",
    "#             r= ir.add(hr)\n",
    "#             rt = self.sigmoid(r)\n",
    "            \n",
    "#             iff=embedded_words[i].matmul(self.Wif)\n",
    "#             hff=hidden.matmul(   self.Whf)\n",
    "#             ff= iff.add(hff)\n",
    "#             fft = self.sigmoid(ff)\n",
    "            \n",
    "#             ig=embedded_words[i].matmul(self.Wig)\n",
    "#             hg=hidden.matmul(   self.Whg)\n",
    "#             g= ig.add(hg)\n",
    "#             gt = self.tanh(g)\n",
    "            \n",
    "#             io=embedded_words[i].matmul(self.Wio)\n",
    "#             ho=hidden.matmul(   self.Who)\n",
    "#             o= io.add(ho)\n",
    "#             ot = self.sigmoid(o)\n",
    "            \n",
    "#             c = fft*c + rt*gt\n",
    "#             hidden = ot*self.tanh(c)\n",
    "        \n",
    "#         out = self.fc(hidden)\n",
    "        \n",
    "#         sig = self.sigmoid(out)\n",
    "#         return sig, hidden\n",
    "    \n",
    "# class NetworkGRU_(nn.Module):\n",
    "    \n",
    "#     def __init__(self, n_vocab, n_embed, hidden_node, n_output, layers):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.Wir = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "#         self.Whr = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "#         self.Wiz = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "#         self.Whz = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "#         self.Win = nn.Parameter(torch.randn( (n_embed,hidden_node), requires_grad=True, dtype=torch.float))\n",
    "#         self.Whn = nn.Parameter(torch.randn( (hidden_node,hidden_node) , requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "#         self.hidden_node = hidden_node\n",
    "#         self.layers = layers\n",
    "        \n",
    "#         self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "#         self.fc = nn.Linear(n_hidden, n_output)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.tanh = nn.Tanh()\n",
    "#         self.dropout = nn.Dropout(0.6)\n",
    "        \n",
    "        \n",
    "#     def forward (self, input_words):                    # => (batch size, sent len)\n",
    "        \n",
    "#         embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "#         embedded_words = embedded_words.permute(1,0,2)   #  (seq_length,batch_size,  n_embed)\n",
    "#         hidden = torch.zeros(input_words.size(0), self.hidden_node).to(device)  # batch-node\n",
    "        \n",
    "#         for i in range(input_words.size(1)):           #for i in seq_length\n",
    "\n",
    "#             ir=embedded_words[i].matmul(self.Wir)\n",
    "#             hr=hidden.matmul(   self.Whr)\n",
    "#             r= ir.add(hr)\n",
    "#             rt = self.sigmoid(r)\n",
    "            \n",
    "#             #print(rt.shape)\n",
    "            \n",
    "#             iz=embedded_words[i].matmul(self.Wiz)\n",
    "#             hz=hidden.matmul(   self.Whz)\n",
    "#             z= iz.add(hz)\n",
    "#             zt = self.sigmoid(z)\n",
    "            \n",
    "#             iN=embedded_words[i].matmul(self.Win)\n",
    "#             hN=hidden.matmul(   self.Whz)*rt\n",
    "#             N= iN.add(hN)\n",
    "#             Nt = self.tanh(N)\n",
    "            \n",
    "#             hidden = (1-zt)*Nt + zt*hidden\n",
    "        \n",
    "#         out = self.fc(hidden)\n",
    "        \n",
    "#         sig = self.sigmoid(out)\n",
    "#         return sig, hidden"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taco",
   "language": "python",
   "name": "taco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
